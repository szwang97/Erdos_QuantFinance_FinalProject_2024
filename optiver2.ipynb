{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-25T20:28:32.826369Z","iopub.execute_input":"2024-04-25T20:28:32.827249Z","iopub.status.idle":"2024-04-25T20:28:33.201753Z","shell.execute_reply.started":"2024-04-25T20:28:32.827210Z","shell.execute_reply":"2024-04-25T20:28:33.200705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cbt\nfrom sklearn.model_selection import TimeSeriesSplit\nimport optiver2023\nimport warnings\nfrom warnings import simplefilter\nwarnings.filterwarnings('ignore')\nsimplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:28:38.119340Z","iopub.execute_input":"2024-04-25T20:28:38.120333Z","iopub.status.idle":"2024-04-25T20:28:43.173786Z","shell.execute_reply.started":"2024-04-25T20:28:38.120300Z","shell.execute_reply":"2024-04-25T20:28:43.172899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:28:46.880147Z","iopub.execute_input":"2024-04-25T20:28:46.880550Z","iopub.status.idle":"2024-04-25T20:29:04.942824Z","shell.execute_reply.started":"2024-04-25T20:28:46.880519Z","shell.execute_reply":"2024-04-25T20:29:04.941855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sum(df['target'].isna()))\ndf['target'].describe()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:29:08.653076Z","iopub.execute_input":"2024-04-25T20:29:08.653758Z","iopub.status.idle":"2024-04-25T20:29:09.518401Z","shell.execute_reply.started":"2024-04-25T20:29:08.653724Z","shell.execute_reply":"2024-04-25T20:29:09.517268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(subset=['target'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:29:12.540369Z","iopub.execute_input":"2024-04-25T20:29:12.540751Z","iopub.status.idle":"2024-04-25T20:29:12.921404Z","shell.execute_reply.started":"2024-04-25T20:29:12.540724Z","shell.execute_reply":"2024-04-25T20:29:12.920303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Engineering function\ndef generate_features(df):\n    features = ['seconds_in_bucket', 'imbalance_buy_sell_flag', 'imbalance_size', 'matched_size',\n                'bid_size', 'ask_size', 'reference_price', 'far_price', 'near_price', 'ask_price',\n                'bid_price', 'wap', 'imb_s1', 'imb_s2']\n    \n    # Imbalance features\n    df['imb_s1'] = (df['bid_size'] - df['ask_size']) / (df['bid_size'] + df['ask_size'])\n    df['imb_s2'] = (df['imbalance_size'] - df['matched_size']) / (df['matched_size'] + df['imbalance_size'])\n    \n    prices = ['reference_price', 'far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n    \n    for i, a in enumerate(prices):\n        for j, b in enumerate(prices[i+1:], i+1):\n            df[f'{a}_{b}_diff'] = df[a] - df[b]\n            features.append(f'{a}_{b}_diff')\n            df[f'{a}_{b}_delta'] = (df[a] - df[b]) / (df[a] + df[b])\n            features.append(f'{a}_{b}_delta')\n    \n    for i,a in enumerate(prices):\n        for j,b in enumerate(prices):\n            for k,c in enumerate(prices):\n                if i>j and j>k:\n                    max_ = df[[a,b,c]].max(axis=1)\n                    min_ = df[[a,b,c]].min(axis=1)\n                    mid_ = df[[a,b,c]].sum(axis=1)-min_-max_\n\n                    df[f'{a}_{b}_{c}_imb2'] = (max_-mid_)/(mid_-min_)\n                    features.append(f'{a}_{b}_{c}_imb2')\n    \n    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n        \n    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n        for window in [1, 2, 4, 8, 16]:\n            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window)\n            df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window, fill_method=None)\n    \n    df = additional_features(df)\n    \n    feature_names = [w for w in df.columns if w not in [\"row_id\", \"time_id\", \"target\"]]\n    \n    return df, feature_names\n\ndef additional_features(df):\n    df['signed_imb_size'] = df['imbalance_buy_sell_flag'] * df['imbalance_size']\n    df['mid_price'] = (df['ask_price'] + df['bid_price']) / 2\n    df['volume'] = df['bid_size'] + df['ask_size']\n    df['imb_ratio'] = df['imbalance_size'] / df['matched_size']\n    df['size_imbalance'] = df['bid_size']/df['ask_size']\n    df['imb_bid_r'] = df['imbalance_size']/df['bid_size']\n    df['imb_ask_r'] = df['imbalance_size']/df['ask_size']\n    df['mat_bid_ask_r'] = df.eval('matched_size/(bid_size+ask_size)')\n    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n    df[\"spread_intensity\"] = df.groupby(['stock_id'])['ask_price_bid_price_diff'].diff()\n    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n    df['market_urgency'] = df['ask_price_bid_price_diff'] * df['imb_s1']\n    df['delta_bid_ask_size'] = (df['bid_size'] - df['ask_size']) / (df['bid_size'] + df['ask_size'] + 1)\n    df['bid_ask_matched_r'] = (df['bid_size'] - df['ask_size']) / (df['matched_size'] + 1)\n    \n    prices = ['reference_price', 'far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n    # Discrete derivatives\n    for i, a in enumerate(prices):\n        df[f'{a}_first_derivative'] = df.groupby(['stock_id'])[a].diff()\n    for i, a in enumerate(sizes):\n        df[f'{a}_first_derivative'] = df.groupby(['stock_id'])[a].diff()\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:29:17.281387Z","iopub.execute_input":"2024-04-25T20:29:17.282285Z","iopub.status.idle":"2024-04-25T20:29:17.304197Z","shell.execute_reply.started":"2024-04-25T20:29:17.282252Z","shell.execute_reply":"2024-04-25T20:29:17.303054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply feature engineering to the training data\ndf_train, feature_names = generate_features(df)\nX = df_train[feature_names].values\ny = df_train['target'].values\nprint(f\"Number of Features: {len(feature_names)}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:29:21.914212Z","iopub.execute_input":"2024-04-25T20:29:21.914713Z","iopub.status.idle":"2024-04-25T20:31:33.552250Z","shell.execute_reply.started":"2024-04-25T20:29:21.914682Z","shell.execute_reply":"2024-04-25T20:31:33.551121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Training with Hyperparameter Tuning and Cross-Validation\nfrom lightgbm import early_stopping\n\ndef train_model(X, y, n_splits=5, tr_folds=[3,4]):\n    models = []\n    tscv = TimeSeriesSplit(n_splits=n_splits)\n    \n    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n        if fold not in tr_folds:\n            continue\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n        # LightGBM model\n#         model_lgb = lgb.LGBMRegressor(objective='regression_l1', n_estimators=500, learning_rate=0.05)\n#         model_lgb.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n#                       callbacks=[early_stopping(stopping_rounds=50)])\n\n#         # XGBoost model\n#         print(\"Training with XGBoost\")\n#         model_xgb = xgb.XGBRegressor(objective='reg:squarederror', \n#                                      n_estimators=500, \n#                                      learning_rate=0.05, \n#                                      early_stopping_rounds=50)\n#         model_xgb.fit(X_train, y_train, eval_set=[(X_test, y_test)] , verbose=20)\n\n#         # CatBoost model\n        print(\"Training with CatBoost: Fold {fold}\")\n        model_cbt = cbt.CatBoostRegressor(loss_function='MAE',\n                                          eval_metric = 'MAE',\n                                          iterations=1000, \n                                          learning_rate=5e-3, \n                                          early_stopping_rounds=50,\n                                          task_type=\"GPU\",\n                                          devices='0',\n                                          boosting_type='Plain',\n                                          l2_leaf_reg=10,\n                                          thread_count=-1,\n                                          verbose=True)\n        \n                        \n        model_cbt.fit(X_train, y_train, eval_set=[(X_test, y_test)],  verbose=20)\n        \n        yval_pred = model_cbt.predict(X_test)\n        loss_val = np.mean(np.abs(yval_pred - y_test))\n        print(f\"After fold {fold}, the validation loss is {loss_val:.3f}\")\n\n        models.append(model_cbt)\n\n    return models","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:33:01.163182Z","iopub.execute_input":"2024-04-25T20:33:01.164223Z","iopub.status.idle":"2024-04-25T20:33:01.176852Z","shell.execute_reply.started":"2024-04-25T20:33:01.164178Z","shell.execute_reply":"2024-04-25T20:33:01.175714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the models\nmodels = train_model(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:33:05.292985Z","iopub.execute_input":"2024-04-25T20:33:05.293938Z","iopub.status.idle":"2024-04-25T20:47:54.504784Z","shell.execute_reply.started":"2024-04-25T20:33:05.293904Z","shell.execute_reply":"2024-04-25T20:47:54.503649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env = optiver2023.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:48:54.333911Z","iopub.execute_input":"2024-04-25T20:48:54.334685Z","iopub.status.idle":"2024-04-25T20:48:54.339365Z","shell.execute_reply.started":"2024-04-25T20:48:54.334647Z","shell.execute_reply":"2024-04-25T20:48:54.338329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (test, revealed_targets, prediction) in iter_test:\n    test_df, all_features = generate_features(test)\n    X = test_df[feature_names]\n    prediction['target'] = models[0].predict(X)\n    env.predict(prediction)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:48:58.345242Z","iopub.execute_input":"2024-04-25T20:48:58.346148Z","iopub.status.idle":"2024-04-25T20:49:36.475683Z","shell.execute_reply.started":"2024-04-25T20:48:58.346107Z","shell.execute_reply":"2024-04-25T20:49:36.474777Z"},"trusted":true},"execution_count":null,"outputs":[]}]}